{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import random\n",
    "from rasterio.features import shapes\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "from osgeo import ogr, gdal\n",
    "from torchvision.transforms import transforms\n",
    "from tqdm import tqdm\n",
    "from shapely.geometry import polygon\n",
    "from utils import generate_patch_coordinates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join('C:','Users','bhatt','OneDrive','Desktop','butwal data')\n",
    "image_dir = \"C:\\\\Users\\\\bhatt\\\\OneDrive\\\\Desktop\\\\butwal data\\\\Orthomosaics Output\\\\Butwal Orthomosaics Only\"\n",
    "mask_dir = \"C:\\\\Users\\\\bhatt\\\\OneDrive\\\\Documents\\\\ArcGIS\\\\Projects\\\\MyProject33\"\n",
    "current_image_file_name = 'Mission 2.tif'\n",
    "current_mask_file_name = 'Buildings.shp'\n",
    "\n",
    "# Path to the image file in .tif format\n",
    "image_path = os.path.join(image_dir, current_image_file_name)\n",
    "# Path to the shape file containing the landcover classes in .shp format\n",
    "mask_path = os.path.join(mask_dir,\n",
    "                         current_mask_file_name)\n",
    "# Path to the shape file containing the landcover classes in .shp format\n",
    "# mask_path = os.path.join(mask_dir,\n",
    "#                          current_mask_file_name)\n",
    "output12_dir = os.path.join('.', 'output12')\n",
    "os.makedirs(output12_dir, exist_ok=True)\n",
    "\n",
    "rasterized_dir = os.path.join(output12_dir, 'rasterized_outputs')\n",
    "os.makedirs(rasterized_dir, exist_ok=True)\n",
    "# rasterized_dir = os.path.join(output_dir, 'rasterized_outputs')\n",
    "# os.makedirs(rasterized_dir, exist_ok=True)\n",
    "rasterized_file_name = \"Result12.tif\"\n",
    "rasterized_file_path = os.path.join(rasterized_dir, rasterized_file_name)\n",
    "patch_size = 513\n",
    "stride = 256\n",
    "boundary = [3053710.461731, 751158.377075, 3055429.699707, 753175.112122]\n",
    "patch_output_dir = os.path.join(output12_dir, f\"{patch_size}x{patch_size}\")\n",
    "os.makedirs(patch_output_dir, exist_ok=True)\n",
    "labels_output_dir = os.path.join(patch_output_dir, 'labels')\n",
    "os.makedirs(labels_output_dir, exist_ok=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_shape_file_path = mask_path\n",
    "image_file_path = image_path\n",
    "\n",
    "gdalformat = 'GTiff'\n",
    "datatype = gdal.GDT_Float32\n",
    "\n",
    "# Get projection info from reference image\n",
    "Image = gdal.Open(image_file_path, gdal.GA_ReadOnly)\n",
    "\n",
    "# Open Shapefile\n",
    "Shapefile = ogr.Open(mask_shape_file_path)\n",
    "Shapefile_layer = Shapefile.GetLayer()\n",
    "\n",
    "# Rasterise\n",
    "print(\"Rasterizing shapefile...\")\n",
    "\n",
    "Output = gdal.GetDriverByName(gdalformat).Create(rasterized_file_path, Image.RasterXSize, Image.RasterYSize, 1,\n",
    "                                                 datatype,\n",
    "                                                 options=['COMPRESS=DEFLATE'])\n",
    "Output.SetProjection(Image.GetProjectionRef())\n",
    "Output.SetGeoTransform(Image.GetGeoTransform())\n",
    "\n",
    "# Write data to band 1\n",
    "Band = Output.GetRasterBand(1)\n",
    "Band.SetNoDataValue(0)\n",
    "\n",
    "gdal.RasterizeLayer(Output, [1], Shapefile_layer, options=['ATTRIBUTE=Class_id'])\n",
    "\n",
    "# Close datasets\n",
    "Band = None\n",
    "Output = None\n",
    "Image = None\n",
    "Shapefile = None\n",
    "\n",
    "print(\"Rasterization of shapefile completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the rasters\n",
    "with rasterio.open(image_path) as raster1:\n",
    "    temp_img = raster1.read()  # Read raster1 into numpy array\n",
    "\n",
    "with rasterio.open(rasterized_file_path) as raster2:\n",
    "    temp_mask = raster2.read(1)  # Read raster2 into numpy array\n",
    "\n",
    "labels, count = np.unique(temp_mask, return_counts=True)  #Check for each channel. All channels are identical\n",
    "print('Unique values in mask: ', labels)\n",
    "print('Counts of unique values: ', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(rasterized_file_path, \"r\") as src:\n",
    "    mask_data = src.read()\n",
    "    mask_meta = src.meta\n",
    "\n",
    "print(np.unique(mask_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_patches\n",
    "# image_path=\"C:\\\\Users\\\\bhatt\\\\OneDrive\\Desktop\\\\butwal data\\\\Orthomosaics Output\\\\Butwal Orthomosaics Only\\\\Mission 1.tif\"\n",
    "# rasterized_file_path=\"C:\\\\Users\\\\bhatt\\\\OneDrive\\\\Desktop\\\\semprj\\\\aerial-satellite-imagery-segmentation-nepal\\\\output11\\\\rasterized_outputs\\\\Result11.tif\"\n",
    "# patch_size= 513\n",
    "# stride=256\n",
    "# patch_output_dir=\"C:\\\\Users\\\\bhatt\\\\OneDrive\\\\Desktop\\\\semprj\\\\aerial-satellite-imagery-segmentation-nepal\\\\output11\\\\513x513\"\n",
    "create_patches(image_path, rasterized_file_path, patch_output_dir, patch_size, stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_output_dir=r\"C:\\Users\\bhatt\\OneDrive\\Desktop\\semprj\\aerial-satellite-imagery-segmentation-nepal\\output12\\513x513\"\n",
    "image_files = [f for f in os.listdir(patch_output_dir + \"\\\\images\") if f.endswith('.jpg')]\n",
    "\n",
    "# Select a random image file\n",
    "random_image_file = random.choice(image_files)\n",
    "\n",
    "# Construct the full paths to the image and mask files\n",
    "temp_image_path = os.path.join(patch_output_dir, \"images\", random_image_file)\n",
    "temp_mask_path = os.path.join(patch_output_dir, \"masks\", random_image_file.replace('.jpg', '_mask.jpg'))\n",
    "\n",
    "# Open the image and mask files using Rasterio\n",
    "with rasterio.open(temp_image_path) as src:\n",
    "    image = src.read().astype(float)\n",
    "    image_transform = src.transform\n",
    "\n",
    "with rasterio.open(temp_mask_path) as src:\n",
    "    mask = src.read()\n",
    "    mask_transform = src.transform\n",
    "\n",
    "# The image data read by Rasterio is in (bands, rows, cols) order\n",
    "# Convert the image data to (rows, cols, bands) order for visualization\n",
    "transposed_image = image.transpose((1, 2, 0))\n",
    "\n",
    "if 0 not in np.unique(transposed_image):\n",
    "    # Scale the image data to be between 0 and 1 for better visualization\n",
    "    transposed_image -= transposed_image.min()\n",
    "    transposed_image /= transposed_image.max()\n",
    "\n",
    "    # Create plots\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15, 15))\n",
    "\n",
    "    # Display the image\n",
    "    ax[0].imshow(transposed_image)\n",
    "    ax[0].set_title(\"Image\")\n",
    "\n",
    "    # Display the mask\n",
    "    transposed_mask = mask.transpose((1, 2, 0))\n",
    "\n",
    "    ax[1].imshow(transposed_mask)\n",
    "    ax[1].set_title(\"Mask\")\n",
    "    print(np.unique(mask))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    print('Image shape: ', image.shape)\n",
    "    print('Mask shape: ', mask.shape)\n",
    "else:\n",
    "    print(\"Blank data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Get list of image files\n",
    "image_files = [f for f in os.listdir(patch_output_dir + \"\\\\images\") if f.endswith('.jpg')]\n",
    "print(image_files)\n",
    "# Select a random image file\n",
    "random_image_file = random.choice(image_files)\n",
    "\n",
    "# Construct the full paths to the image and mask files\n",
    "temp_image_path = os.path.join(patch_output_dir, \"images\", random_image_file)\n",
    "temp_mask_path = os.path.join(patch_output_dir, \"masks\", random_image_file.replace('.jpg', '_mask.jpg'))\n",
    "\n",
    "# Open the image and mask files using Rasterio\n",
    "with rasterio.open(temp_image_path) as src:\n",
    "    image = src.read().astype(float)\n",
    "    image_transform = src.transform\n",
    "# temp_mask_path=r\"C:\\Users\\bhatt\\OneDrive\\Desktop\\semprj\\aerial-satellite-imagery-segmentation-nepal\\Output_mg\\513x513\\masks\\test\\Mission4patch_955_mask.jpg\"\n",
    "\n",
    "with rasterio.open(temp_mask_path) as src:\n",
    "    mask = src.read()\n",
    "    mask_transform = src.transform\n",
    "print(np.unique(mask))\n",
    "# The image data read by Rasterio is in (bands, rows, cols) order\n",
    "# Convert the image data to (rows, cols, bands) order for visualization\n",
    "transposed_image = image.transpose((1, 2, 0))\n",
    "\n",
    "# Scale the image data to be between 0 and 1 for better visualization\n",
    "transposed_image -= transposed_image.min()\n",
    "transposed_image /= transposed_image.max()\n",
    "\n",
    "# Create plots\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Display the image\n",
    "ax[0].imshow(transposed_image)\n",
    "ax[0].set_title(\"Image\")\n",
    "\n",
    "# Display the first channel of the mask\n",
    "ax[1].imshow(mask[0,:,:], cmap='gray')\n",
    "ax[1].set_title(\"Mask Channel 1\")\n",
    "\n",
    "# Display the second channel of the mask\n",
    "ax[2].imshow(mask[1,:,:], cmap='gray')\n",
    "ax[2].set_title(\"Mask Channel 2\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Create plots\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "# # Combine the channels into a single image\n",
    "# combined_mask = np.stack((mask[0,:,:], mask[1,:,:], np.zeros_like(mask[0,:,:])), axis=-1)\n",
    "\n",
    "# # Display the combined mask\n",
    "# ax.imshow(combined_mask)\n",
    "# ax.set_title(\"Combined Mask\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "print('Image shape:', image.shape)\n",
    "print('Mask shape:', mask.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(patch_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generator2 import NepalDataGenerator\n",
    "from generator2 import NepalDataset\n",
    "from utils import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = patch_output_dir\n",
    "in_channels = 4\n",
    "num_classes = 4\n",
    "batch_size = 4\n",
    "shuffle = True\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "])\n",
    "\n",
    "dataset = NepalDataset(data_path, transform=transform)\n",
    "print(f\"Dataset size: {format(len(dataset))}\")\n",
    "data_generator = NepalDataGenerator(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "print(f\"Data generator size: {format(len(data_generator))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_images_to_show = 4 # Number of images to show from the batch\n",
    "\n",
    "images, masks = data_generator.__next__()  # Get the batch of images and masks\n",
    "\n",
    "if no_of_images_to_show > batch_size:\n",
    "    no_of_images_to_show = batch_size\n",
    "\n",
    "for i in range(0, no_of_images_to_show):\n",
    "    image = images[i].permute(1, 2, 0).numpy()  # Access individual image and convert to numpy array\n",
    "    mask = masks[i].squeeze().numpy()  # Access individual mask and convert to numpy array\n",
    "    visualize(image, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLO V8 preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from shapely.geometry import Polygon\n",
    "import tifffile\n",
    "\n",
    "\n",
    "def mask_to_polygons(img_path, mask_path):\n",
    "    '''\n",
    "    Convierte una máscara de imagen en polígonos. Devuelve dos listas:\n",
    "    - Lista de polígonos de shapely sin normalizar\n",
    "    - Lista de polígonos de shapely normalizados (coordenadas entre 0 y 1)\n",
    "\n",
    "    Args:\n",
    "        img_path (str): Ruta al archivo de imagen original.\n",
    "        mask_path (str): Ruta al archivo de la máscara en escala de grises.\n",
    "    '''\n",
    "\n",
    "    mask =tifffile.imread(mask_path)\n",
    "\n",
    "    # mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Calcula los contornos \n",
    "    mask = mask.astype(bool)\n",
    "    #contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # convertimos los contornos a polígonos de Label Studio\n",
    "    polygons = []\n",
    "    normalized_polygons = []\n",
    "    for contour in contours:\n",
    "\n",
    "        # Lo meto en un try porque la extraccion de polígonos que hace el opencv a partir de la máscara\n",
    "        # a veces genera polígonos de menos de 4 vértices, que no tiene sentido por no ser cerrados, \n",
    "        # provocando que falle al convertir a polígno de shapely\n",
    "\n",
    "        try:\n",
    "            polygon = contour.reshape(-1, 2).tolist()\n",
    "\n",
    "            # normalizamos las coordenadas entre 0 y 1 porque así lo requiere YOLOv8\n",
    "            normalized_polygon = [[round(coord[0] / mask.shape[1], 4), round(coord[1] / mask.shape[0], 4)] for coord in\n",
    "                                  polygon]\n",
    "\n",
    "            # Convertimos a objeto poligono de shapely (sin normalizar)\n",
    "            polygon_shapely = Polygon(polygon)\n",
    "            simplified_polygon = polygon_shapely.simplify(0.85, preserve_topology=True)\n",
    "            polygons.append(simplified_polygon)\n",
    "\n",
    "            # normalizdos\n",
    "            normalized_polygons.append(Polygon(normalized_polygon))\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    return polygons, normalized_polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_to_polygons_per_class(img_path, mask_path):\n",
    "    # Map grayscale mask values to your class indices\n",
    "    class_mapping = {0: 0, 1: 1,2:2}\n",
    "\n",
    "    mask = tifffile.imread(mask_path)\n",
    "\n",
    "    polygons_per_class = {}\n",
    "    for mask_value in np.unique(mask):\n",
    "        # Look up class index using mask value, if no mapping is found then continue\n",
    "        class_index = class_mapping.get(mask_value)\n",
    "        if class_index is None:\n",
    "            continue\n",
    "\n",
    "        class_mask = np.where(mask == mask_value, 1, 0).astype(np.uint8)\n",
    "\n",
    "        contours, _ = cv2.findContours(class_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "        polygons = []\n",
    "        for contour in contours:\n",
    "            try:\n",
    "                polygon = contour.reshape(-1, 2).tolist()\n",
    "\n",
    "                normalized_polygon = [\n",
    "                    \n",
    "                    [round(coord[0] / mask.shape[1], 4), round(coord[1] / mask.shape[0], 4)]\n",
    "                    for coord in polygon\n",
    "                ]\n",
    "\n",
    "                if class_index not in polygons_per_class:\n",
    "                    polygons_per_class[class_index] = []\n",
    "                polygons_per_class[class_index].append(Polygon(normalized_polygon))\n",
    "\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "    return polygons_per_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "input_dir = os.path.join(patch_output_dir, 'masks')\n",
    "output_dir = labels_output_dir\n",
    "\n",
    "for j in os.listdir(input_dir):\n",
    "    image_path = os.path.join(input_dir, j)\n",
    "    polygons, normalized_polygons = mask_to_polygons(image_path, image_path)  # Separate lists for each class\n",
    "\n",
    "    # print the polygons\n",
    "    file_name_without_ext = os.path.splitext(j)[0]\n",
    "    if file_name_without_ext.endswith('_mask'):\n",
    "        file_name_without_ext = file_name_without_ext[:-5]\n",
    "\n",
    "    with open('{}.txt'.format(os.path.join(output_dir, file_name_without_ext)), 'w') as f:\n",
    "        for class_label in range(3):\n",
    "            for polygon in normalized_polygons:\n",
    "                f.write('{} '.format(class_label))  # Add class label at the beginning of each line\n",
    "                if isinstance(polygon, Polygon):\n",
    "                    x, y = polygon.exterior.xy\n",
    "                    for i in range(len(x)):\n",
    "                        f.write('{} {}\\t'.format(x[i], y[i]))\n",
    "                f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "input_dir = os.path.join(patch_output_dir, 'masks')\n",
    "output_dir = labels_output_dir\n",
    "\n",
    "\n",
    "for j in os.listdir(input_dir):\n",
    "    image_path = os.path.join(input_dir, j)\n",
    "    polygons_per_class = mask_to_polygons_per_class(image_path, image_path)\n",
    "\n",
    "    # print the polygons\n",
    "    file_name_without_ext = os.path.splitext(j)[0]\n",
    "    if file_name_without_ext.endswith('_mask'):\n",
    "        file_name_without_ext = file_name_without_ext[:-5]\n",
    "    \n",
    "    with open('{}.txt'.format(os.path.join(output_dir, file_name_without_ext)), 'w') as f:\n",
    "        for class_label, polygons in polygons_per_class.items():\n",
    "            for polygon in polygons:\n",
    "                f.write('{} '.format(class_label))  # Add class label at the beginning of each line\n",
    "                x, y = polygon.exterior.xy\n",
    "                for i in range(len(x)):\n",
    "                    f.write('{} {}\\t'.format(x[i], y[i]))\n",
    "                f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def split_dataset_into_train_val_test(input_folder, output_folder, ratio=(0.7, 0.15, 0.15)):\n",
    "#     assert sum(ratio) == 1, \"Ratios must add up to 1.\"\n",
    "\n",
    "#     # Get all file names in the input folder\n",
    "#     all_files = os.listdir(input_folder)\n",
    "#     np.random.shuffle(all_files)\n",
    "\n",
    "#     num_files = len(all_files)\n",
    "#     train_files = all_files[:int(num_files * ratio[0])]\n",
    "#     val_files = all_files[int(num_files * ratio[0]):int(num_files * (ratio[0] + ratio[1]))]\n",
    "#     test_files = all_files[int(num_files * (ratio[0] + ratio[1])):]\n",
    "\n",
    "#     # Create output directories\n",
    "#     for dir in ['train', 'val', 'test']:\n",
    "#         os.makedirs(os.path.join(output_folder, dir), exist_ok=True)\n",
    "\n",
    "#     # Move files to respective directories\n",
    "#     for file in train_files:\n",
    "#         shutil.move(os.path.join(input_folder, file), os.path.join(output_folder, 'train', file))\n",
    "\n",
    "#     for file in val_files:\n",
    "#         shutil.move(os.path.join(input_folder, file), os.path.join(output_folder, 'val', file))\n",
    "\n",
    "#     for file in test_files:\n",
    "#         shutil.move(os.path.join(input_folder, file), os.path.join(output_folder, 'test', file))\n",
    "\n",
    "\n",
    "# directories = ['images', 'labels', 'masks']\n",
    "# patch_output_directory = patch_output_dir\n",
    "\n",
    "# for directory in directories:\n",
    "#     input_folder = os.path.join(patch_output_directory, directory)\n",
    "#     output_folder = os.path.join(patch_output_directory, directory)\n",
    "#     split_dataset_into_train_val_test(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "def split_dataset_into_train_val_test(input_folder_images, input_folder_masks, output_folder, ratio=(0.7, 0.15, 0.15)):\n",
    "    assert sum(ratio) == 1, \"Ratios must add up to 1.\"\n",
    "\n",
    "    # Get all image file names in the input folder\n",
    "    all_image_files = [f for f in os.listdir(input_folder_images) if f.endswith('.jpg')]\n",
    "    np.random.shuffle(all_image_files)\n",
    "\n",
    "    num_files = len(all_image_files)\n",
    "    train_files = all_image_files[:int(num_files * ratio[0])]\n",
    "    val_files = all_image_files[int(num_files * ratio[0]):int(num_files * (ratio[0] + ratio[1]))]\n",
    "    test_files = all_image_files[int(num_files * (ratio[0] + ratio[1])):]\n",
    "\n",
    "    # Create output directories\n",
    "    for dir in ['train', 'val', 'test']:\n",
    "        os.makedirs(os.path.join(output_folder, 'images', dir), exist_ok=True)\n",
    "        os.makedirs(os.path.join(output_folder, 'masks', dir), exist_ok=True)\n",
    "\n",
    "    # Function to move files\n",
    "    def move_files(files, subset):\n",
    "        for file in files:\n",
    "            base_name = os.path.splitext(file)[0]\n",
    "            image_file = file\n",
    "            mask_file = base_name + '_mask.jpg'\n",
    "\n",
    "            src_image_path = os.path.join(input_folder_images, image_file)\n",
    "            src_mask_path = os.path.join(input_folder_masks, mask_file)\n",
    "            dest_image_path = os.path.join(output_folder, 'images', subset, image_file)\n",
    "            dest_mask_path = os.path.join(output_folder, 'masks', subset, mask_file)\n",
    "\n",
    "            # Check if the mask file exists before moving\n",
    "            if os.path.exists(src_mask_path):\n",
    "                shutil.move(src_image_path, dest_image_path)\n",
    "                shutil.move(src_mask_path, dest_mask_path)\n",
    "            else:\n",
    "                print(f\"Warning: Mask file {src_mask_path} not found for image file {src_image_path}. Skipping.\")\n",
    "\n",
    "    move_files(train_files, 'train')\n",
    "    move_files(val_files, 'val')\n",
    "    move_files(test_files, 'test')\n",
    "\n",
    "# Directories\n",
    "patch_output_directory = patch_output_dir\n",
    "\n",
    "input_folder_images = os.path.join(patch_output_directory, 'images')\n",
    "input_folder_masks = os.path.join(patch_output_directory, 'masks')\n",
    "\n",
    "split_dataset_into_train_val_test(input_folder_images, input_folder_masks, patch_output_directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import os\n",
    "\n",
    "\n",
    "# def merge_all_files(directory):\n",
    "#     main_folders = ['images', 'labels', 'masks']\n",
    "#     subfolders = ['test', 'train', 'val']\n",
    "\n",
    "#     for main_folder in main_folders:\n",
    "#         main_folder_path = os.path.join(directory, main_folder)\n",
    "\n",
    "#         for subfolder in subfolders:\n",
    "#             subfolder_path = os.path.join(main_folder_path, subfolder)\n",
    "\n",
    "#             # merge all files in subfolder to main_folder\n",
    "#             for filename in os.listdir(subfolder_path):\n",
    "#                 shutil.move(os.path.join(subfolder_path, filename), main_folder_path)\n",
    "\n",
    "#             # remove subfolder\n",
    "#             shutil.rmtree(subfolder_path)\n",
    "# # function call\n",
    "# merge_all_files(patch_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8m-seg.pt')\n",
    "\n",
    "model.train(data='config.yaml', epochs=100, imgsz=512, single_cls=False,patience=30,optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=model.val()\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model_path = \"C:\\\\Users\\\\bhatt\\\\runs\\\\segment\\\\train10\\\\weights\\\\best.pt\"\n",
    "\n",
    "image_path = \"C:\\\\Users\\\\bhatt\\\\OneDrive\\\\Desktop\\\\semprj\\\\aerial-satellite-imagery-segmentation-nepal\\\\output\\\\512x512\\\\images\\\\test\\\\patch_1700.jpg\"\n",
    "\n",
    "img= cv2.imread(image_path)\n",
    "H, W, _ = img.shape\n",
    "\n",
    "model = YOLO(model_path)\n",
    "\n",
    "results = model(img)\n",
    "\n",
    "# Process results list\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    result.show()  # display to screen\n",
    "    result.save(filename='result.jpg')  # save to disk\n",
    "# \n",
    "# for result in results:\n",
    "#     for j,mask in enumerate(result.masks.data):\n",
    "#         mask=mask.cpu().numpy()*255\n",
    "#         mask=cv2.resize(mask, (W,H))\n",
    "#         visualize(img,mask)\n",
    "#         print(f\"Class of mask {j}: {result.masks.data.names[j]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# import tifffile\n",
    "# patch_output_dir = r'output\\512x512'\n",
    "# input_dir = os.path.join(patch_output_dir, 'masks')\n",
    "# # output_dir = labels_output_dir\n",
    "\n",
    "# for j in os.listdir(input_dir):\n",
    "#     print(j)\n",
    "#     image_path = os.path.join(input_dir, j)\n",
    "#     # mask = tifffile.imread(image_path)\n",
    "#     plt.imread(r\"output\\512x512\\masks\\test\\patch_381_mask.jpg\")\n",
    "#     plt.show()\n",
    "#     # image_path = os.path.join(input_dir, j)\n",
    "#     # polygons, normalized_polygons = mask_to_polygons(image_path, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
